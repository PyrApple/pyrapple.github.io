---
layout: default
title: Oculus Project
description: Binaural audio rendering individualization in VR.
thumbnail: or-thumbnail.jpg
---

<!-- INSTALL EVERTims -->
<section id="oculus-project">
  <div class="container">
    <div class="col-xs-12 text-justify">

      <h2 class="text-left"> Oculus Project (2019 - WIP) </h2>

      <p>In collaboration with the <a href="https://tech.fb.com/ar-vr/">Facebook Reality Labs</a>, the overall project investigates how far we need to push binaural audio rendering quality in VR for players to get life-like reactions for various types of games. The first two experiments will focus on the benefits of binaural rendering on players accuracy and efficiency: first assessing the impact of HRTF individualization, second that of training on a given set of HRTFs.</p>

      <h3>Phase 1: Get everything up and ready</h3>

      <h4>The headset just arrived</h4>
      <img class="img-responsive borderless" src="{{ site.baseurl }}/img/or-cv1.jpg" alt="">

      <h4>CAD of the VR Room</h4>
      <div class="col-xs-12 col-lg-6">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-mocap-room-render.jpg" alt="">
      </div>
      <div class="col-xs-12 col-lg-6">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-mocap-room-render-2.jpg" alt="">
      </div>

      <h4>VR Room install: check</h4>
      <img class="img-responsive " src="{{ site.baseurl }}/img/or-room-1.jpg" alt="">


      <h3 id="hrtf-indiv-video">Phase 2: HRTF individualization experiment </h3>

      <h4>In-game video of the HRTF experiment</h4>
      <div class="embed-responsive embed-responsive-16by9 ">
        <iframe src="https://www.youtube.com/embed/q6muds1qW-w?rel=0" frameborder="0" allowfullscreen></iframe>
      </div>
      
      <p>
        This is a short footage of a subject running the HRTF individualization experience. The point here was to assess the impact of individualized HRTF in a VR game where, needless to say, the whole design was built around target localization. HRTF individualization can roughly be seen an adaptation of the audio rendering to players “listening profile”. With individual rendering comes i.e. an improved capacity for audio source localization in the VR scene. The drawback is that establishing a player's profile is a pain at the moment (for the player at least). The goal of the experiment was to check whether this pain is worth it, and if so for which “level” of gameplay (no real need for high speed and accurate localization when everything is moving so slow you can randomly shoot and still get away with it).
      </p>

      <h3>Phase 3: HRTF training experiment</h3>
      <p class="text-justify">
      The objective is to design a VR experience / game to accelerate HRTF selection and learning. The first design proposed was based on a harvesting mechanism, coupled with throwing things here and there to score points. The harvesting forced players to pay attention to audio-visual targets of known position in space (hear it spawn, check where it is, continue playing while it ripens, harvest it before it goes bad). The throwing things, along with a few other game-play induced player moving audio sources around their head, was supposed to further help with the learning (proprioception).
      </p>

      <h4>HRTF training experiment v1 storyboards </h4>

      <div class="col-xs-12 col-md-6">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-hrtf-training-story-board-v2-2.jpg"  alt="">
      </div>
      <div class="col-xs-12 col-md-6">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-hrtf-training-story-board-v2-1.jpg"  alt="">
      </div>
      <div class="col-xs-12">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-hrtf-training-story-board-v1.jpg"  alt="">
      </div>

      <h4>HRTF training experiment v1 let's play </h4>
      <div class="embed-responsive embed-responsive-16by9 ">
        <iframe src="https://www.youtube.com/embed/mZwYrd824e4" frameborder="0" allowfullscreen></iframe>
      </div>

      <p class="text-justify">
      The first design was finally discarded. Beta tests showed that not only participants had a hard time understanding the game mechanics, but that playing it did not result in any substantial HRTF-wise improvement (i.e. audio localization accuracy). A second version was designed, switching gears: if the first implementation was a game turned into a learning experience, the second was a learning experience made into a game. We listed all the known problems of non-individualized binaural rendering (localization-wise), and created learning scenarios to expose and overcome them one by one. This new design capitalizes on skill learning itself as an incentive, presenting participants with a tool that we ourselves would want to use to quickly learn a new set of ears.
      </p>

      <h4>HRTF training experiment v2 let's play </h4>
      <div class="embed-responsive embed-responsive-16by9 ">
        <iframe src="https://www.youtube.com/embed/j2FFSz-h_Jo" frameborder="0" allowfullscreen></iframe>
      </div>

      <h4>Keynote of the HRTF training experiment (<a href="https://www.gamesoundcon.com/">GameSound conference</a> 2020)</h4>
      <div class="embed-responsive embed-responsive-16by9 ">
        <iframe src="https://www.youtube.com/embed/JGRNJu_05Uk" frameborder="0" allowfullscreen></iframe>
      </div>


      <h3>Phase 4: Work in progress</h3>
      <!-- <h3>Phase 4: HRTF overlap in an AR context</h3> -->

      <h4>HMD upgrade: Quests 1 and 2 are here</h4>
      <div class="col-xs-12 col-lg-6">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-quest1.jpg" alt="">
      </div>
      <div class="col-xs-12 col-lg-6">
        <img class="img-responsive " src="{{ site.baseurl }}/img/or-quest2.jpg" alt="">
      </div>
      
    </div>
  </div>
</section>
